{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Reading and Preprocessing Data\n",
    "\n",
    "input_path = pd.read_csv('green_tripdata_2018-01.csv')\n",
    "output_path = ''\n",
    "\n",
    "\n",
    "def data_preprocessing(input_path, output_path):\n",
    "    \"\"\"\n",
    "    Returns the df of shape (744, 252) first two cols are 'Day', 'Hour'. df is for month 1 with data for each hour\n",
    "    \"\"\"\n",
    "\n",
    "    print('[*] Reading the Original Dataset')\n",
    "    # raw_dataset = pd.read_csv('../dataset/green_taxi.csv')\n",
    "    raw_dataset =input_path\n",
    "\n",
    "    print('[*] Extracting Useful Data')\n",
    "    edited_dataset = raw_dataset[['lpep_pickup_datetime', 'PULocationID']]\n",
    "    edited_dataset_npy = np.array(edited_dataset)\n",
    "\n",
    "    days = np.array([i + 1 for i in range(31)])\n",
    "    hours = np.array([i for i in range(24)])\n",
    "\n",
    "    number_of_hours = len(days) * len(hours)\n",
    "\n",
    "    days_hours_data = np.zeros((number_of_hours, 2))\n",
    "    day = 1\n",
    "    hour = 0\n",
    "\n",
    "    for i in range(number_of_hours):\n",
    "        days_hours_data[i, 0] = day\n",
    "        days_hours_data[i, 1] = hour\n",
    "\n",
    "        if hour == 23:\n",
    "            hour = 0\n",
    "            day += 1\n",
    "        else:\n",
    "            hour += 1\n",
    "\n",
    "    print('[*] Creating an Intermediate Dataset')\n",
    "\n",
    "    intermediate_dataset = pd.DataFrame(days_hours_data, columns=['Day', 'Hour'], dtype=int)\n",
    "\n",
    "    new_columns = [str(item) for item in sorted(np.unique(edited_dataset_npy[:, 1]))]\n",
    "\n",
    "    for new_column in new_columns:\n",
    "        intermediate_dataset[new_column] = np.zeros((number_of_hours, 1), dtype=int)\n",
    "\n",
    "    for item in edited_dataset_npy:\n",
    "        date = item[0]\n",
    "        item_day = int(date[8:10])\n",
    "        item_hour = int(date[11:13])\n",
    "        pick_up_location_id = str(item[1])\n",
    "        intermediate_dataset.at[(item_day - 1) * 24 + item_hour, pick_up_location_id] += 1\n",
    "\n",
    "    intermediate_dataset.to_csv(output_path)\n",
    "    return intermediate_dataset\n",
    "\n",
    "\n",
    "df = pd.read_csv(output_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"/Users/nargesrezaei/Desktop/pre_processed_data.csv\"\n",
    "input_path = \"green_tripdata_2018-01.csv\"\n",
    "df = data_preprocessing(input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Reading the Original Dataset\n",
      "[*] Extracting Useful Data\n",
      "[['2018-01-01 00:18:50' 236]\n",
      " ['2018-01-01 00:30:26' 43]\n",
      " ['2018-01-01 00:07:25' 74]\n",
      " ...\n",
      " ['2018-01-31 23:19:43' 41]\n",
      " ['2018-01-31 23:57:59' 42]\n",
      " ['2018-01-31 23:30:45' 193]]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-25ebf30777bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0medited_dataset_npy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medited_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medited_dataset_npy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0medited_dataset_npy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Reading and Preprocessing Data\n",
    "\n",
    "input_path = pd.read_csv('green_tripdata_2018-01.csv')\n",
    "#output_path = ''\n",
    "\n",
    "\n",
    "#def data_preprocessing(input_path, output_path):\n",
    "    \n",
    "    #Returns the df of shape (744, 252) first two cols are 'Day', 'Hour'. df is for month 1 with data for each hour\n",
    "    \n",
    "\n",
    "print('[*] Reading the Original Dataset')\n",
    "    # raw_dataset = pd.read_csv('../dataset/green_taxi.csv')\n",
    "raw_dataset =input_path\n",
    "\n",
    "print('[*] Extracting Useful Data')\n",
    "edited_dataset = raw_dataset[['lpep_pickup_datetime', 'PULocationID']]\n",
    "edited_dataset_npy = np.array(edited_dataset)\n",
    "print(edited_dataset_npy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Creating an Intermediate Dataset\n",
      "     Day  Hour\n",
      "0      1     0\n",
      "1      1     1\n",
      "2      1     2\n",
      "3      1     3\n",
      "4      1     4\n",
      "..   ...   ...\n",
      "739   31    19\n",
      "740   31    20\n",
      "741   31    21\n",
      "742   31    22\n",
      "743   31    23\n",
      "\n",
      "[744 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "days = np.array([i + 1 for i in range(31)])\n",
    "hours = np.array([i for i in range(24)])\n",
    "\n",
    "number_of_hours = len(days) * len(hours)\n",
    "\n",
    "days_hours_data = np.zeros((number_of_hours, 2))\n",
    "day = 1\n",
    "hour = 0\n",
    "\n",
    "for i in range(number_of_hours):\n",
    "    days_hours_data[i, 0] = day\n",
    "    days_hours_data[i, 1] = hour\n",
    "\n",
    "    if hour == 23:\n",
    "        hour = 0\n",
    "        day += 1\n",
    "    else:\n",
    "        hour += 1\n",
    "\n",
    "print('[*] Creating an Intermediate Dataset')\n",
    "\n",
    "intermediate_dataset = pd.DataFrame(days_hours_data, columns=['Day', 'Hour'], dtype=int)\n",
    "print(intermediate_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '3', '6', '7', '8', '9', '10', '11', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '28', '29', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '106', '107', '108', '109', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '173', '174', '175', '176', '177', '178', '179', '180', '181', '182', '183', '184', '185', '186', '187', '188', '189', '190', '191', '192', '193', '194', '195', '196', '197', '198', '200', '201', '202', '203', '204', '205', '206', '207', '208', '209', '210', '211', '212', '213', '214', '215', '216', '217', '218', '219', '220', '221', '222', '223', '224', '225', '226', '227', '228', '229', '230', '231', '232', '233', '234', '235', '236', '237', '238', '239', '240', '241', '242', '243', '244', '245', '246', '247', '248', '249', '250', '251', '252', '253', '254', '255', '256', '257', '258', '259', '260', '261', '262', '263', '264', '265']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_columns = [str(item) for item in sorted(np.unique(edited_dataset_npy[:, 1]))]\n",
    "print(new_columns)\n",
    "len(new_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for new_column in new_columns:\n",
    "        intermediate_dataset[new_column] = np.zeros((number_of_hours, 1), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Day', 'Hour', '1', '3', '6', '7', '8', '9', '10', '11',\n",
       "       ...\n",
       "       '256', '257', '258', '259', '260', '261', '262', '263', '264', '265'],\n",
       "      dtype='object', length=252)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intermediate_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Day  Hour  1  3  6  7  8  9  10  11  ...  256  257  258  259  260  261  \\\n",
      "0      1     0  0  0  0  0  0  0   0   0  ...    0    0    0    0    0    0   \n",
      "1      1     1  0  0  0  0  0  0   0   0  ...    0    0    0    0    0    0   \n",
      "2      1     2  0  0  0  0  0  0   0   0  ...    0    0    0    0    0    0   \n",
      "3      1     3  0  0  0  0  0  0   0   0  ...    0    0    0    0    0    0   \n",
      "4      1     4  0  0  0  0  0  0   0   0  ...    0    0    0    0    0    0   \n",
      "..   ...   ... .. .. .. .. .. ..  ..  ..  ...  ...  ...  ...  ...  ...  ...   \n",
      "739   31    19  0  0  0  0  0  0   0   0  ...    0    0    0    0    0    0   \n",
      "740   31    20  0  0  0  0  0  0   0   0  ...    0    0    0    0    0    0   \n",
      "741   31    21  0  0  0  0  0  0   0   0  ...    0    0    0    0    0    0   \n",
      "742   31    22  0  0  0  0  0  0   0   0  ...    0    0    0    0    0    0   \n",
      "743   31    23  0  0  0  0  0  0   0   0  ...    0    0    0    0    0    0   \n",
      "\n",
      "     262  263  264  265  \n",
      "0      0    0    0    0  \n",
      "1      0    0    0    0  \n",
      "2      0    0    0    0  \n",
      "3      0    0    0    0  \n",
      "4      0    0    0    0  \n",
      "..   ...  ...  ...  ...  \n",
      "739    0    0    0    0  \n",
      "740    0    0    0    0  \n",
      "741    0    0    0    0  \n",
      "742    0    0    0    0  \n",
      "743    0    0    0    0  \n",
      "\n",
      "[744 rows x 252 columns]\n"
     ]
    }
   ],
   "source": [
    "print(intermediate_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for item in edited_dataset_npy:\n",
    "        date = item[0]\n",
    "        item_day = int(date[8:10])\n",
    "        item_hour = int(date[11:13])\n",
    "        pick_up_location_id = str(item[1])\n",
    "        intermediate_dataset.at[(item_day - 1) * 24 + item_hour, pick_up_location_id] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Day  Hour  1  3  6    7  8  9  10  11  ...  256  257  258  259  260  261  \\\n",
      "0      1     0  0  0  0  140  0  0   1   2  ...   57    4    0    0   56    0   \n",
      "1      1     1  0  0  0  175  1  0   0   0  ...   73    2    1    0   57    0   \n",
      "2      1     2  0  0  0  164  0  0   1   0  ...   83    2    0    1   54    0   \n",
      "3      1     3  0  0  0  116  0  0   1   0  ...   87    1    0    0   48    0   \n",
      "4      1     4  1  1  0   92  0  0   0   0  ...   49    1    0    0   46    0   \n",
      "..   ...   ... .. .. ..  ... .. ..  ..  ..  ...  ...  ...  ...  ...  ...  ...   \n",
      "739   31    19  0  1  0  106  0  1   0   0  ...   10    0    2    0   46    0   \n",
      "740   31    20  0  0  0   81  0  0   0   0  ...   10    1    0    1   32    0   \n",
      "741   31    21  0  0  0   83  0  0   0   0  ...   12    1    0    0   32    0   \n",
      "742   31    22  0  0  0   51  0  1   0   0  ...   15    0    1    0   28    0   \n",
      "743   31    23  0  0  0   33  0  0   0   0  ...   24    0    0    0   22    0   \n",
      "\n",
      "     262  263  264  265  \n",
      "0      0    0    2    0  \n",
      "1      0    1    2    3  \n",
      "2      0    1    3    2  \n",
      "3      0    4    5    2  \n",
      "4      0    0    4    1  \n",
      "..   ...  ...  ...  ...  \n",
      "739    0    0    2    0  \n",
      "740    0    4    4    0  \n",
      "741    0    1    1    0  \n",
      "742    0    2    0    0  \n",
      "743    0    0    1    1  \n",
      "\n",
      "[744 rows x 252 columns]\n"
     ]
    }
   ],
   "source": [
    "print(intermediate_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2018-01-01 00:18:50', 236], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edited_dataset_npy[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_dataset.to_csv('preprocess_dataframe.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
